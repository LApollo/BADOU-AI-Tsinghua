以下为运行结果：
<br>PyDev console: starting.
<br>Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:34:17) [MSC v.1929 64 bit (AMD64)] on win32
<br>>>> runfile('D:/badou/draft.py', wdir='D:/badou')
<br>
<br>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
<br>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\MNIST\raw\train-images-idx3-ubyte.gz
<br><font color="LightCoral">100.0%</font>
<br>Extracting ./data\MNIST\raw\train-images-idx3-ubyte.gz to ./data\MNIST\raw
<br>
<br>Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
<br>Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\MNIST\raw\train-labels-idx1-ubyte.gz
<br><font color="LightCoral">102.8%</font>
<br>Extracting ./data\MNIST\raw\train-labels-idx1-ubyte.gz to ./data\MNIST\raw
<br>
<br>Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
<br>Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\MNIST\raw\t10k-images-idx3-ubyte.gz
<br><font color="LightCoral">100.0%</font>
<br>Extracting ./data\MNIST\raw\t10k-images-idx3-ubyte.gz to ./data\MNIST\raw
<br>
<br>Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
<br>Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\MNIST\raw\t10k-labels-idx1-ubyte.gz
<br><font color="LightCoral">112.7%</font>
<br>Extracting ./data\MNIST\raw\t10k-labels-idx1-ubyte.gz to ./data\MNIST\raw

| Log                  | Result      | Log                  | Result      | Log                  | Result      |
|----------------------|-------------|----------------------|-------------|----------------------|-------------|
| [epoch1, 0.053333%]  | loss: 0.023 | [epoch2, 0.053333%]  | loss: 0.015 | [epoch3, 0.053333%]  | loss: 0.015 |
| [epoch1, 5.386667%]  | loss: 1.769 | [epoch2, 5.386667%]  | loss: 1.509 | [epoch3, 5.386667%]  | loss: 1.502 |
| [epoch1, 10.720000%] | loss: 1.606 | [epoch2, 10.720000%] | loss: 1.524 | [epoch3, 10.720000%] | loss: 1.494 |
| [epoch1, 16.053333%] | loss: 1.564 | [epoch2, 16.053333%] | loss: 1.509 | [epoch3, 16.053333%] | loss: 1.498 |
| [epoch1, 21.386667%] | loss: 1.548 | [epoch2, 21.386667%] | loss: 1.501 | [epoch3, 21.386667%] | loss: 1.495 |
| [epoch1, 26.720000%] | loss: 1.535 | [epoch2, 26.720000%] | loss: 1.510 | [epoch3, 26.720000%] | loss: 1.501 |
| [epoch1, 32.053333%] | loss: 1.541 | [epoch2, 32.053333%] | loss: 1.505 | [epoch3, 32.053333%] | loss: 1.501 |
| [epoch1, 37.386667%] | loss: 1.538 | [epoch2, 37.386667%] | loss: 1.511 | [epoch3, 37.386667%] | loss: 1.496 |
| [epoch1, 42.720000%] | loss: 1.533 | [epoch2, 42.720000%] | loss: 1.508 | [epoch3, 42.720000%] | loss: 1.494 |
| [epoch1, 48.053333%] | loss: 1.528 | [epoch2, 48.053333%] | loss: 1.504 | [epoch3, 48.053333%] | loss: 1.503 |
| [epoch1, 53.386667%] | loss: 1.537 | [epoch2, 53.386667%] | loss: 1.514 | [epoch3, 53.386667%] | loss: 1.500 |
| [epoch1, 58.720000%] | loss: 1.523 | [epoch2, 58.720000%] | loss: 1.501 | [epoch3, 58.720000%] | loss: 1.495 |
| [epoch1, 64.053333%] | loss: 1.519 | [epoch2, 64.053333%] | loss: 1.506 | [epoch3, 64.053333%] | loss: 1.498 |
| [epoch1, 69.386667%] | loss: 1.532 | [epoch2, 69.386667%] | loss: 1.507 | [epoch3, 69.386667%] | loss: 1.504 |
| [epoch1, 74.720000%] | loss: 1.518 | [epoch2, 74.720000%] | loss: 1.504 | [epoch3, 74.720000%] | loss: 1.495 |
| [epoch1, 80.053333%] | loss: 1.506 | [epoch2, 80.053333%] | loss: 1.498 | [epoch3, 80.053333%] | loss: 1.499 |
| [epoch1, 85.386667%] | loss: 1.514 | [epoch2, 85.386667%] | loss: 1.503 | [epoch3, 85.386667%] | loss: 1.496 |
| [epoch1, 90.720000%] | loss: 1.517 | [epoch2, 90.720000%] | loss: 1.501 | [epoch3, 90.720000%] | loss: 1.496 |
| [epoch1, 96.053333%] | loss: 1.518 | [epoch2, 96.053333%] | loss: 1.508 | [epoch3, 96.053333%] | loss: 1.496 |
|                      |             |                      |             |                      |             |
| Log                  | Result      | Log                  | Result      | Log                  | Result      |
| [epoch4, 0.053333%]  | loss: 0.015 | [epoch5, 0.053333%]  | loss: 0.015 |                      |             |
| [epoch4, 5.386667%]  | loss: 1.491 | [epoch5, 5.386667%]  | loss: 1.501 |                      |             |
| [epoch4, 10.720000%] | loss: 1.495 | [epoch5, 10.720000%] | loss: 1.495 |                      |             |
| [epoch4, 16.053333%] | loss: 1.496 | [epoch5, 16.053333%] | loss: 1.487 |                      |             |
| [epoch4, 21.386667%] | loss: 1.490 | [epoch5, 21.386667%] | loss: 1.493 |                      |             |
| [epoch4, 26.720000%] | loss: 1.499 | [epoch5, 26.720000%] | loss: 1.487 |                      |             |
| [epoch4, 32.053333%] | loss: 1.506 | [epoch5, 32.053333%] | loss: 1.490 |                      |             |
| [epoch4, 37.386667%] | loss: 1.498 | [epoch5, 37.386667%] | loss: 1.495 |                      |             |
| [epoch4, 42.720000%] | loss: 1.496 | [epoch5, 42.720000%] | loss: 1.492 |                      |             |
| [epoch4, 48.053333%] | loss: 1.494 | [epoch5, 48.053333%] | loss: 1.494 |                      |             |
| [epoch4, 53.386667%] | loss: 1.493 | [epoch5, 53.386667%] | loss: 1.494 |                      |             |
| [epoch4, 58.720000%] | loss: 1.495 | [epoch5, 58.720000%] | loss: 1.497 |                      |             |
| [epoch4, 64.053333%] | loss: 1.486 | [epoch5, 64.053333%] | loss: 1.497 |                      |             |
| [epoch4, 69.386667%] | loss: 1.496 | [epoch5, 69.386667%] | loss: 1.497 |                      |             |
| [epoch4, 74.720000%] | loss: 1.498 | [epoch5, 74.720000%] | loss: 1.502 |                      |             |
| [epoch4, 80.053333%] | loss: 1.494 | [epoch5, 80.053333%] | loss: 1.493 |                      |             |
| [epoch4, 85.386667%] | loss: 1.501 | [epoch5, 85.386667%] | loss: 1.495 |                      |             |
| [epoch4, 90.720000%] | loss: 1.495 | [epoch5, 90.720000%] | loss: 1.492 |                      |             |
| [epoch4, 96.053333%] | loss: 1.488 | [epoch5, 96.053333%] | loss: 1.500 |                      |             |

<br>Finished Training
<br>Evaluating ...
<br>Accuracy of the network on the test images: 95.38%

<br>P.S. 由于batch size = 32，因此60000张图片被分成1875个batch，我们设定的是每100个batch输出一次进度，因此最后75个batch的结果没有输出。